<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e3b46ca7acd66c6855abed975a02083f";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
		

<head>
	<title>DSAA 2023 Special Session on Computational Imaging, Vision, Linguistics and Language (CIVIL)</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/dsaa2022.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>


<body class="is-preload">
	<div id="page-wrapper">

		<!-- Header -->
		<header id="header">
			<font color="#FFFFFF">
				<h1 id="logo"><a href="dsaa2023.html"><font color="#FFFFFF">CIVIL @ DSAA 2023</font></a></h1>
			<nav id="nav">
				<ul>
<!--					<li><a href="dsaa2023.html#ks">Keynote Speaker</a></li>-->
<!--					<li><a href="dsaa2023.html#ap">Accepted Papers</a></li>-->
					<li><a href="dsaa2023.html#cfp">Call for Papers</a></li>
					<li><a href="dsaa2023.html#sub">Submission</a></li>
					<li><a href="dsaa2023.html#ip">Important Policies</a></li>
					<li><a href="dsaa2023.html#oc">Organizing Committee</a></li>
<!--					<li><a href="dsaa2023.html#news">News</a></li>-->
				</ul>
			</nav>
			</font>
		</header>

		<div class="box alt" align="center">
						<!--Row 1 of highlighted papers-->
						<div class="row gtr-50 gtr-uniform">

							<div class="col-12"><span class="image fit"><img src="images/dsaa2023/greece.jpeg" alt="" /></span>
					</div>
						</div>
		</div>

		<!-- Main -->
		<div id="main" class="wrapper style1">
			<div class="container">
				<header class="major">
					<h2>Computational Imaging, Vision, Linguistics and Language (CIVIL)</h2>
					<p>The 10th IEEE International Conference on Data Science and Advanced Analytics <br>
						Thessaloniki, Greece (9-13 october 2023)</p>
				</header>

				<!-- keynote speaker -->
<!--				<section id="ks">-->
<!--					<header align="center">-->
<!--						<h3><font color="#8000ff">Keynote Speaker</font></h3>-->
<!--					</header>-->

<!--					<p>-->
<!--						<div class="col-3 col-5-xsmall" align="center">-->
<!--								<span class="image align-center"><img src="images/dsaa2022/liangzhao_resize.jpg" alt="" /></span>-->
<!--								<header>-->
<!--									<h3>Liang Zhao</h3>-->
<!--									<p>Emory University</p>-->
<!--								</header>-->
<!--							</div>-->
<!--					</p>-->
<!--					<header>-->
<!--						<h4><font color="#8000ff">Title</font></h4>-->
<!--					</header>-->
<!--					<p>Graph Neural Networks for Dynamic Network Modeling and Inverse Problems</p>-->

<!--					<header>-->
<!--						<h4><font color="#8000ff">Abstract</font></h4>-->
<!--					</header>-->
<!--					<p>Deep learning techniques have achieved tremendous success in continuous data like image and audio. They then extended such success into other data such as network- structured data which are ubiquitous in many scientific such as molecules and societal domains such as Internet of Things. Networks are commonly evolving over time, resulting in temporal networks. Analyzing the time-variant and time-invariant aspects of networks are critical research issues in temporal networks, which benefit wide range of applications such as mobility network simulation, information diffusion, and graph topology evolution. Historically, their modeling and analyses typically rely on the network generation principles predefined by human heuristics and prior knowledge. Such methods usually fit well towards the properties that the predefined principles are tailored for, but usually cannot do well for the others. However, in many application domains like the aforementioned ones, the network properties and generation principles are largely unknown. The recent research frontier on graph neural network provides a data-driven alternative for network representation learning and analysis. In this talk, I will first give a background of graph neural networks and then introduce our recent works on temporal networks. Finally, I will also mention our recent work on end-to-end source localization of graph diffusion process.</p>-->

<!--					<header>-->
<!--						<h4><font color="#8000ff">Biography</font></h4>-->
<!--					</header>-->
<!--					<p>Dr. Liang Zhao is an assistant professor at the Department of Compute Science at Emory University. Before that, he was an assistant professor in the Department of Information Science and Technology and the Department of Computer Science at George Mason University. He obtained his Ph.D. degree as Outstanding PhD student in 2016 from Computer Science Department at Virginia Tech in the United States. His research interests include data mining and machine learning, with special interests in spatiotemporal and network data mining, deep learning on graphs, nonconvex optimization, and interpretable machine learning. He has published over a hundred papers in top-tier conferences and journals such as KDD, TKDE, ICDM, ICLR, NeurIPS, Proceedings of the IEEE, TKDD, CSUR, IJCAI, AAAI, and WWW. He won NSF Career Award in 2020 and Jeffress Trust Award in 2019. He also won Amazon Research Award in 2020 and Meta Research Award in 2022. He was honored to be a “CIFellow Mentor” in 2021. He was ranked as “Top 20 Rising Star in Data Mining” by Microsoft Search in 2016. He won several the Best Paper Award and Candidates such as Best Paper Award in ICDM 2019, Best Paper Candidate in ICDM 2021, Best Paper Award Shortlist in WWW 2021, and Best Paper Candidate in ACM SIGSPATIAL 2022. He is an IEEE senior member.</p>-->

<!--					<hr />-->
<!--				</section>-->

				<!-- Accepted Papers -->
<!--				<section id="ap">-->
<!--					<header align="center">-->
<!--						<h3><font color="#8000ff">Accepted Papers</font></h3>-->
<!--					</header>-->

<!--					(Paper ID. Paper Title)-->


<!--					<ul>-->
<!--						<li>8. PATE: Property, Amenities, Traffic and Emotions Coming Together for Real Estate Price Prediction</li>-->
<!--						<li>106. Large-Scale Traffic Congestion Prediction based on Multimodal Fusion and Representation Mapping</li>-->
<!--						<li>179. Positive emotions help rank negative reviews for sellers and producers in e-commerce</li>-->
<!--						<li>191. What Really Drives the Spread of COVID-19 Tweets: A Revisit from Perspective of Content</li>-->
<!--						<li>374. Disentangling the Growth of Blockchain-based Networks by Graph Evolution Rule Mining</li>-->
<!--						<li>381. Simulating Spreading of Multiple Interacting Processes in Complex Networks</li>-->
<!--						<li>384. Modeling the impact of external influence on green behavior spreading in multilayer financial networks</li>-->
<!--						<li>404. Improving Source Localization by Perturbing Graph Diffusion</li>-->
<!--						<li>432. H4M: Heterogeneous, Multi-source, Multi-modal, Multi-view and Multi-distributional Dataset for Socioeconomic Analytics in the Case of Beijing</li>-->

<!--					</ul>-->
<!--					<hr />-->
<!--				</section>-->

				<!-- Contact -->
				<section id="cfp">
					<header align="center">
						<h3><font color="#8000ff">Call for Papers</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Important Dates</font></h4>
					</header>


					<ul>
						<li>Paper Submission Deadline: May 22, 2023</li>
						<li>Paper Notification: July 17, 2023</li>
						<li>Camera-ready Submission: August 7, 2023</li>
					</ul>

					<header>
						<h4><font color="#8000ff">Topics of Interest</font></h4>
					</header>

					<p>The general aim of this special session is to address visual and textual tasks emerging from a computational perspective, by overcoming challenges in the computing domain and building artifacts that usefully process vision and language.</p>

					Topics of interest include but are not limited to:

					<ul>

					• Visual Tasks<br>
					• Textual Tasks<br>
						• Vision-Language Tasks

					</ul>
					<header>
						<h5><font color="#8000ff">• Visual Tasks</font></h5>
					</header>
					<ul>
						– Computational Photography
<br>– Image & Video Sensing, Representation, Modeling, and Registration
<br>– Image & Video Motion Estimation, Registration, and Fusion
<br>– Image & Video Synthesis, Rendering, and Visualization
<br>– Image & Video Restoration and Enhancement
<br>– Image & Video Interpretation and Understanding
<br>– Image & Video Compression, Coding, and Transmission
<br>– Visual Detection, Recognition, Retrieval, and Classification
<br>– Color, Multi-spectral, and Hyper-spectral Imaging
<br>– Image & Video Biometrics, Forensics, and Security
<br>– Stereoscopic, Multi-view, and 3D Processing
<br>– Biomedical and Biological Image Processing
<br>– Image & Video Quality Models
					</ul>
					<header>
						<h5><font color="#8000ff">• Textual Tasks</font></h5>
					</header>
					<ul>
						– Computational Social Science and Cultural Analytics
<br>– Dialogue and Interactive Systems
<br>– Discourse and Pragmatics
<br>– Information Extraction
<br>– Information Retrieval and Text Mining
<br>– Linguistic Theories, Cognitive Modeling, and Psycholinguistics
<br>– Machine Translation and Multilinguality
<br>– Phonology, Morphology, and Word Segmentation
<br>– Question Answering
<br>– Resources and Evaluation
<br>– Sentence-level Semantics, Textual Inference, and Other Areas
<br>– Sentiment Analysis, Stylistic Analysis, and Argument Mining
<br>– Speech and Multimodality
<br>– Summarization
					</ul>

					<header>
						<h5><font color="#8000ff">• Vision-Language Tasks</font></h5>
					</header>
					<ul>
						– Image-Sentence Retrieval
<br>– Phrase Grounding
<br>– Text-to-Clip
<br>– Image Captioning
<br>– Object Sketching
<br>– Video-text Retrieval
<br>– Visual Question Answering
					</ul>
					<hr />
				</section>

				<!-- HKU-PS -->
				<section id="sub">
					<header align="center">
						<h3><font color="#8000ff">Submission</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Submission Instructions</font></h4>
					</header>
<!--					<ul>TBA</ul>-->
					<ul>
						<li>Step 1: Login and enter DSAA conference in EasyChair. Website: <a href="https://easychair.org/conferences/?conf=dsaa2023" target="_blank">https://easychair.org/conferences/?conf=dsaa2023</a></li>
						<li>Step 2: Select your role as "author". From the top menu, click the "New Submission" button, and then select "Special Session: Computational Imaging, Vision, Linguistics and Language" to continue.</li>
						<li>Step 3: Enter your paper information and then use the "Submit" button at the bottom of the form.</li>
					</ul>

					<header>
						<h4><font color="#8000ff">Paper Length, Formatting, and Reviewing</font></h4>
					</header>
					<ul>
						<li>The length of each paper submitted should be no more than 10 pages, and formatted following the standard 2-column U.S. letter style of IEEE Conference template. See the <a href="http://www.ieee.org/conferences_events/conferences/publishing/templates.html" target="_blank">IEEE Proceedings Author Guidelines</a> for further information and instructions.</li>
						<li>All submissions will be double-blind reviewed by the Program Committee on the basis of technical quality, relevance to the scope of the special session, originality, significance, and clarity. The names and affiliations of authors must not appear in the submissions, and bibliographic references must be adjusted to preserve author anonymity. Submissions failing to comply with paper formatting and authors anonymity will be rejected without reviews.</li>
						<li>Authors are also encouraged to submit supplementary materials, i.e., providing the source code and data through a GitHub-like public repository to support the reproducibility of their research results.</li>
					</ul>

					<header>
						<h4><font color="#8000ff">Proceedings, Indexing and Special Issues</font></h4>
					</header>
					<ul>
						All accepted full-length special session papers will be published by IEEE in the DSAA main conference proceedings under its Special Session scheme. All papers will be submitted for inclusion in the IEEEXplore Digital Library. The conference proceedings will be submitted for EI indexing through INSPEC by IEEE.
<!--						<li>Organizers of Special Session may additionally, arrange for special issues to further publish the extended journal versions of the papers. Several past special sessions have published special issues with the International Journal of Data Science and Analytics (JDSA, Springer).</li>-->
					</ul>

					<hr />
				</section >

				<!-- HKU-PS -->
				<section id="ip">
					<header align="center">
						<h3><font color="#8000ff">Important Policies</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Reproducibility</font></h4>
					</header>
					The advancement of science depends heavily on reproducibility. We strongly recommend that the authors release their code and data to the public. Authors can provide an optional two-page supplement at the end of their submitted paper (it needs to be in the same PDF file and start at page 11). This supplement can only be used to include:
					<ul>
						<li>(i) information necessary for reproducing the experimental results reported in the paper (e.g., various algorithmic and model parameters and configurations, hyper parameter search spaces, details related to data set filtering and train/test splits, software versions, detailed hardware configuration, etc.).</li>
						<li>(ii) any data, pseudo-code and proofs that could not be included in the main page of the manuscript due to space limitations.</li>
					</ul>

					<header>
						<h4><font color="#8000ff">Authorship</font></h4>
					</header>
					<p>The list of authors at the time of submission is considered final and any further changes of the authorship are not allowed.</p>

					<header>
						<h4><font color="#8000ff">Dual submissions</font></h4>
					</header>
					<p>DSAA is an archival publication venue as such submissions that have been previously published, accepted, or are currently under consideration at other peer-review publication venues (i.e., journals, conferences, workshops with published proceedings, etc) are not permitted.</p>

					<header>
						<h4><font color="#8000ff">Conflicts of interest (COI)</font></h4>
					</header>
					<p>COIs must be declared at the time of submission. COIs include employment at the same institution within the past three years, collaborations during the past three years, advisor/advisee relationships, plus family and close friends.</p>

					<header>
						<h4><font color="#8000ff">Attendance</font></h4>
					</header>
					<p>At least one of the authors of each accepted paper must register in full and attend the conference to present the paper. No-show papers will be removed from the IEEE Xplore proceedings.</p>

					<hr />
				</section>

				<!-- HKU-PS -->
				<section id="oc">
					<header align="center">
						<h3><font color="#8000ff">Organizing Committee</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Special Session Chairs</font></h4>
					</header>
					<ul>
						<li>Vagelis Papalexakis, University of California Riverside</li>
						<li>Grant Scott, University of Missouria</li>
					</ul>

					<header>
						<h4><font color="#8000ff">Organizer</font></h4>
					</header>
					<ul>
						<li><a target="_blank" href="https://indigopurple.github.io/">Yaping Zhao</a>, the University of Hong Kong</li>
						Inquiries about this special session should be sent to: <strong><a
							href="mailto:zhaoyp@connect.hku.hk">zhaoyp (at) connect.hku.hk</a></strong>
					</ul>

					<header>
						<h4><font color="#8000ff">Program Committee</font></h4>
					</header>
					TBA
<!--					Chair-->
<!--					<li>Jichang Zhao, Beihang University</li><br>-->
<!--					Members-->
<!--					(Alphabetical order)-->
<!--					<ul>-->
<!--						<li>Ali Hosseiny, Shahid Beheshti University</li>-->
<!--						<li>Andreia Sofia Teixeira, University of Lisbon</li>-->
<!--						<li>Bodong Zhou, Individual Researcher</li>-->
<!--						<li>Briane Paul V. Samson, De La Salle University</li>-->
<!--						<li>Fabiola Pereira, Federal University of Uberlandia</li>-->
<!--						<li>Haitian Zheng, University of Rochester</li>-->
<!--						<li>Hyunuk Kim, Boston University</li>-->
<!--						<li>Jiahui Liu, The University of Hong Kong</li>-->
<!--						<li>Kaiping Chen, University of Wisconsin-Madison</li>-->
<!--						<li>Mengli Yu, Nankai University</li>-->
<!--						<li>Peggy Lindner, University of Houston</li>-->
<!--						<li>Rene C. Batac, De La Salle University</li>-->
<!--						<li>Shan Lu, Central University of Finance and Economics</li>-->
<!--						<li>Songyi Cui, The University of Hong Kong</li>-->
<!--						<li>Stephan Leitner, University of Klagenfurt</li>-->
<!--						<li>Subhayan Mukerjee, National University of Singapore</li>-->
<!--						<li>Xiaoqian Hu, Capital University of Economics and Business</li>-->
<!--						<li>Yang Yang, Beihang University</li>-->
<!--						<li>Yuwei Chuai, Beihang University</li>-->
<!--						<li>Zhenkun Zhou, Capital University of Economics and Business</li>-->
<!--						-->
<!--						-->
<!--					</ul>-->
<!--					<hr />-->
<!--					<hr />-->
				</section>

				<!-- News -->
<!--				<section id="news">-->
<!--					<header align="center">-->
<!--						<h3><font color="#8000ff">News</font></h3>-->
<!--					</header>-->

<!--					<div class="col-12">-->
<!--						<span class="image fit"><img src="images/dsaa2022/flyer4.jpeg" alt="" /></span>-->
<!--					</div>-->
<!--				</section>-->



			</div>
		</div>

<!--		&lt;!&ndash; Footer &ndash;&gt;-->
<!--		<footer id="footer">-->
<!--			<ul class="icons">-->
<!--				<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>-->
<!--				<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>-->
<!--				<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>-->
<!--				<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>-->
<!--				<li><a href="#" class="icon solid alt fa-envelope"><span class="label">Email</span></a></li>-->
<!--			</ul>-->
<!--			<ul class="copyright">-->
<!--				<li>&copy; Untitled. All rights reserved.</li>-->
<!--				<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>-->
<!--			</ul>-->
<!--		</footer>-->

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>