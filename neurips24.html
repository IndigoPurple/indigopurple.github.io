<!DOCTYPE HTML>
<!--
	Landed by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?e3b46ca7acd66c6855abed975a02083f";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
		

<head>
	<title>Urban Dynamics Challenge: AI-driven Insights into Real Estate and Traffic Patterns</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<link rel="stylesheet" href="assets/css/dsaa2022.css" />
	<noscript>
		<link rel="stylesheet" href="assets/css/noscript.css" />
	</noscript>
</head>


<body class="is-preload">
	<div id="page-wrapper">

		<!-- Header -->
		<header id="header">
			<font color="#FFFFFF">
				<h1 id="logo"><a href="neurips24.html"><font color="#FFFFFF">Urban Dynamics Challenge @ NeurIPS 2024</font></a></h1>
			<nav id="nav">
				<ul>
<!--					<li><a href="neurips24.html#ks">Keynote Speaker</a></li>-->
<!--					<li><a href="neurips24.html#ap">Accepted Papers</a></li>-->
					<li><a href="neurips24.html#competition">Competition</a></li>
					<li><a href="neurips24.html#instructions">Instructions</a></li>
					<li><a href="neurips24.html#committee">Committee</a></li>
<!--					<li><a href="neurips24.html#news">News</a></li>-->
				</ul>
			</nav>
			</font>
		</header>

		<div class="box alt" align="center">
						<!--Row 1 of highlighted papers-->
						<div class="row gtr-50 gtr-uniform">

							<div class="col-12"><span class="image fit"><img src="img/neurips24/bg.jpeg" alt="" /></span>
					</div>
						</div>
		</div>

		<!-- Main -->
		<div id="main" class="wrapper style1">
			<div class="container">
				<header class="major">
					<h2>Urban Dynamics Challenge</h2>
					<p>AI-driven Insights into Real Estate and Traffic Patterns</p>
				</header>

				<!-- keynote speaker -->
<!--				<section id="ks">-->
<!--					<header align="center">-->
<!--						<h3><font color="#8000ff">Keynote Speaker</font></h3>-->
<!--					</header>-->

<!--					<p>-->
<!--						<div class="col-3 col-5-xsmall" align="center">-->
<!--								<span class="image align-center"><img src="images/dsaa2022/liangzhao_resize.jpg" alt="" /></span>-->
<!--								<header>-->
<!--									<h3>Liang Zhao</h3>-->
<!--									<p>Emory University</p>-->
<!--								</header>-->
<!--							</div>-->
<!--					</p>-->
<!--					<header>-->
<!--						<h4><font color="#8000ff">Title</font></h4>-->
<!--					</header>-->
<!--					<p>Graph Neural Networks for Dynamic Network Modeling and Inverse Problems</p>-->

<!--					<header>-->
<!--						<h4><font color="#8000ff">Abstract</font></h4>-->
<!--					</header>-->
<!--					<p>Deep learning techniques have achieved tremendous success in continuous data like image and audio. They then extended such success into other data such as network- structured data which are ubiquitous in many scientific such as molecules and societal domains such as Internet of Things. Networks are commonly evolving over time, resulting in temporal networks. Analyzing the time-variant and time-invariant aspects of networks are critical research issues in temporal networks, which benefit wide range of applications such as mobility network simulation, information diffusion, and graph topology evolution. Historically, their modeling and analyses typically rely on the network generation principles predefined by human heuristics and prior knowledge. Such methods usually fit well towards the properties that the predefined principles are tailored for, but usually cannot do well for the others. However, in many application domains like the aforementioned ones, the network properties and generation principles are largely unknown. The recent research frontier on graph neural network provides a data-driven alternative for network representation learning and analysis. In this talk, I will first give a background of graph neural networks and then introduce our recent works on temporal networks. Finally, I will also mention our recent work on end-to-end source localization of graph diffusion process.</p>-->

<!--					<header>-->
<!--						<h4><font color="#8000ff">Biography</font></h4>-->
<!--					</header>-->
<!--					<p>Dr. Liang Zhao is an assistant professor at the Department of Compute Science at Emory University. Before that, he was an assistant professor in the Department of Information Science and Technology and the Department of Computer Science at George Mason University. He obtained his Ph.D. degree as Outstanding PhD student in 2016 from Computer Science Department at Virginia Tech in the United States. His research interests include data mining and machine learning, with special interests in spatiotemporal and network data mining, deep learning on graphs, nonconvex optimization, and interpretable machine learning. He has published over a hundred papers in top-tier conferences and journals such as KDD, TKDE, ICDM, ICLR, NeurIPS, Proceedings of the IEEE, TKDD, CSUR, IJCAI, AAAI, and WWW. He won NSF Career Award in 2020 and Jeffress Trust Award in 2019. He also won Amazon Research Award in 2020 and Meta Research Award in 2022. He was honored to be a “CIFellow Mentor” in 2021. He was ranked as “Top 20 Rising Star in Data Mining” by Microsoft Search in 2016. He won several the Best Paper Award and Candidates such as Best Paper Award in ICDM 2019, Best Paper Candidate in ICDM 2021, Best Paper Award Shortlist in WWW 2021, and Best Paper Candidate in ACM SIGSPATIAL 2022. He is an IEEE senior member.</p>-->

<!--					<hr />-->
<!--				</section>-->

				<!-- Accepted Papers -->
<!--				<section id="ap">-->
<!--					<header align="center">-->
<!--						<h3><font color="#8000ff">Accepted Papers</font></h3>-->
<!--					</header>-->

<!--					(Paper ID. Paper Title)-->


<!--					<ul>-->
<!--						<li>672. Adaptive Compressed Sensing for Real-Time Video Compression, Transmission, and Reconstruction</li>-->
<!--						<li>996. A CNN-Transformer Hybrid Network for Multi-scale object detection</li>-->
<!--						<li>1348. ScaleFace: Uncertainty-aware Deep Metric Learning</li>-->
<!--						<li>5198. Solving Inverse Problems in Compressive Imaging with Score-Based Generative Models</li>-->
<!--&lt;!&ndash;						<li>5683. Cross-Camera Human Motion Transfer by Time Series Analysis</li>&ndash;&gt;-->
<!--						<li>6603. All Translation Tools Are Not Equal: Investigating the Quality of Language Translation for Forced Migration</li>-->
<!--					</ul>-->
<!--					<hr />-->
<!--				</section>-->

				<!-- Contact -->
				<section id="competition">
					<header align="center">
						<h3><font color="#8000ff">Competition</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Important Dates</font></h4>
					</header>


					<ul>
						<li>Competition Launch: July 1, 2024</li>
						<li>Submission Deadline: October 31, 2024</li>
						<li>Results Announcement: December 1, 2024</li>
						<font color="#808080">Time zone: <a target="_blank" href="https://www.timeanddate.com/time/zones/aoe">Anywhere on Earth (AoE)</a></font>
					</ul>


					<header>
						<h4><font color="#8000ff">Tasks</font></h4>
					</header>
					<ol>
						<li><font color="#FF0000">Real Estate Price Estimation</font>: Vital for urban planning and economic policy making, accurate real estate valuation influences investment decisions, taxation policies, and housing affordability initiatives.</li>
						<li><font color="#FF0000">Comprehensive Traffic Forecasting</font>: Addresses the challenge of predicting traffic flow and congestion without prior knowledge of current conditions, essential for long-term urban mobility planning and infrastructure development.</li>
						<li><font color="#FF0000">Targeted Traffic Forecasting</font>: Focuses on short-term traffic management and real-time response strategies, crucial for daily urban operations, emergency response, and event planning.</li>
					</ol>

					<header>
						<h4><font color="#8000ff">Data and Baseline</font></h4>
					</header>

					<p>The dataset and baseline will be released once this competition is launched.</p>

					<hr />
				</section >

				<!-- HKU-PS -->
				<section id="instructions">
					<header align="center">
						<h3><font color="#8000ff">Instructions</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Protocol</font></h4>
					</header>
					To join the competition, participants will follow these steps:
					<ol>
						<li>Registration: Participants will create an account on the chosen competition platform where the competition is hosted.</li>
						<li>Download Data: After registration, participants can download the dataset directly from the competition page. Detailed documentation and a starter kit including data loading scripts and baseline models will be provided.</li>
						<li>Development: Participants develop their models locally, using the provided dataset and baseline code as a starting point.</li>
						<li>Submission: Participants submit their solutions, which should include the prediction results and the source code for model training and prediction. Submissions will be made through the competition platform, where an automated system will evaluate them.</li>
						<li>Evaluation: Submissions will be automatically evaluated based on predefined metrics, and the scores will be displayed on a public leaderboard.</li>
					</ol>
					<p>The competition will consist of two phases: a public phase, where participants can submit solutions and receive immediate feedback on the leaderboard, and a private phase, where the final evaluation is conducted on a hidden test set to determine the competition winners. This structure aims to prevent overfitting and ensure that the models have general applicability.</p>
					<p>To prevent cheating, participants will be required to submit their source code along with their predictions. The code will undergo a review process to ensure that it corresponds to the submitted results and adheres to competition rules. Additionally, the use of external data for model training will be strictly prohibited unless explicitly allowed by the competition rules.</p>

					<header>
						<h4><font color="#8000ff">Rules and Engagement</font></h4>
					</header>
					<ul>
						<li>Eligibility: The competition is open to everyone interested in machine learning and urban analytics. Teams and individuals are welcome.</li>
						<li>Data Use: Participants must use only the provided dataset for training and validation purposes. The use of external data is prohibited.</li>
						<li>Submissions: Each team is allowed to submit a maximum number of entries per day, as specified on the competition platform. The final submission must include both the prediction results and the source code.</li>
						<li>Fair Play: Sharing solutions or code between teams is not allowed. Participants are expected to adhere to the highest standards of academic integrity.</li>
						<li>Privacy and Ethics: Participants must respect privacy and ethical guidelines when handling the dataset and developing models.</li>
					</ul>

					<hr />
				</section>

				<!-- HKU-PS -->
				<section id="committee">
					<header align="center">
						<h3><font color="#8000ff">Committee<br>(Alphabetical Order)</font></h3>
					</header>

					<header>
						<h4><font color="#8000ff">Leader Organizer</font></h4>
					</header>
					<ul>
						<li><a target="_blank" href="https://indigopurple.github.io/">Yaping Zhao</a>, The University of Hong Kong</li>
						Inquiries about this competition should be sent to: <strong><a
							href="mailto:zhaoyp@connect.hku.hk">zhaoyp (at) connect.hku.hk</a></strong>
					</ul>

					<header>
						<h4><font color="#8000ff">Co-organizers</font></h4>
					</header>
<!--					Chair-->
<!--					<li>Jichang Zhao, Beihang University</li><br>-->
<!--					Members-->
<!--					(Alphabetical order)-->
					<ul>
						<li>Bodong Zhou, Individual Researcher</li>
						<li>Edmund Y. Lam, The University of Hong Kong</li>
						<li>Chutian Wang, The University of Hong Kong</li>
						<li>Haitian Zheng, Adobe Research</li>
						<li>Haosen Liu, The University of Hong Kong</li>
						<li>Jiahui Liu, The University of Hong Kong</li>
						<li>Jichang Zhao, Beihang University</li>
						<li>Yuqing Cao, The University of Hong Kong</li>
						<li>Rongzhou Chen, The University of Hong Kong</li>
						<li>Songyi Cui, The University of Hong Kong</li>
					</ul>
<!--					<hr />-->
<!--					<hr />-->
				</section>

				<!-- News -->
<!--				<section id="news">-->
<!--					<header align="center">-->
<!--						<h3><font color="#8000ff">News</font></h3>-->
<!--					</header>-->

<!--					<div class="col-12">-->
<!--						<span class="image fit"><img src="images/dsaa2022/flyer4.jpeg" alt="" /></span>-->
<!--					</div>-->
<!--				</section>-->



			</div>
		</div>

<!--		&lt;!&ndash; Footer &ndash;&gt;-->
<!--		<footer id="footer">-->
<!--			<ul class="icons">-->
<!--				<li><a href="#" class="icon brands alt fa-twitter"><span class="label">Twitter</span></a></li>-->
<!--				<li><a href="#" class="icon brands alt fa-facebook-f"><span class="label">Facebook</span></a></li>-->
<!--				<li><a href="#" class="icon brands alt fa-linkedin-in"><span class="label">LinkedIn</span></a></li>-->
<!--				<li><a href="#" class="icon brands alt fa-github"><span class="label">GitHub</span></a></li>-->
<!--				<li><a href="#" class="icon solid alt fa-envelope"><span class="label">Email</span></a></li>-->
<!--			</ul>-->
<!--			<ul class="copyright">-->
<!--				<li>&copy; Untitled. All rights reserved.</li>-->
<!--				<li>Design: <a href="http://html5up.net">HTML5 UP</a></li>-->
<!--			</ul>-->
<!--		</footer>-->

	</div>

	<!-- Scripts -->
	<script src="assets/js/jquery.min.js"></script>
	<script src="assets/js/jquery.scrolly.min.js"></script>
	<script src="assets/js/jquery.dropotron.min.js"></script>
	<script src="assets/js/jquery.scrollex.min.js"></script>
	<script src="assets/js/browser.min.js"></script>
	<script src="assets/js/breakpoints.min.js"></script>
	<script src="assets/js/util.js"></script>
	<script src="assets/js/main.js"></script>

</body>

</html>